{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers, losses\nimport tensorflow_datasets  as tfds\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport cv2\nimport random\n\nfrom datetime import datetime\nimport itertools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-24T19:10:03.084485Z","iopub.execute_input":"2023-03-24T19:10:03.085425Z","iopub.status.idle":"2023-03-24T19:10:14.298883Z","shell.execute_reply.started":"2023-03-24T19:10:03.085386Z","shell.execute_reply":"2023-03-24T19:10:14.297656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the list of available devices\nprint(tf.config.experimental.list_physical_devices())","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:10:14.301395Z","iopub.execute_input":"2023-03-24T19:10:14.302083Z","iopub.status.idle":"2023-03-24T19:10:14.613455Z","shell.execute_reply.started":"2023-03-24T19:10:14.302033Z","shell.execute_reply":"2023-03-24T19:10:14.612136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect and Initialize the GPUs\nstrategy = tf.distribute.MirroredStrategy()\n!nvidia-smi\n\nprint(\"GPUs initialized.\")","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:10:14.615365Z","iopub.execute_input":"2023-03-24T19:10:14.616226Z","iopub.status.idle":"2023-03-24T19:10:19.631234Z","shell.execute_reply.started":"2023-03-24T19:10:14.616171Z","shell.execute_reply":"2023-03-24T19:10:19.629656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"N_REPLICAS = strategy.num_replicas_in_sync\nprint(f\"Number of available replicas: {N_REPLICAS}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:10:19.633466Z","iopub.execute_input":"2023-03-24T19:10:19.634218Z","iopub.status.idle":"2023-03-24T19:10:19.642464Z","shell.execute_reply.started":"2023-03-24T19:10:19.634169Z","shell.execute_reply":"2023-03-24T19:10:19.641186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (128, 128)\nEPOCHS = 100\nBATCH_SIZE_PER_REPLICA = 32\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * N_REPLICAS \nEARLY_STOP_PATIENCE = 7\n\n# Number of classes to segment the image to\nN_CLASSES = 3\n\n# Define the colormap for plotting the segmented images\nCOLORS = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]        # Red, Green, Blue\nassert len(COLORS) == N_CLASSES\nMASK_CMAP = matplotlib.colors.ListedColormap(COLORS)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:10:19.647181Z","iopub.execute_input":"2023-03-24T19:10:19.648277Z","iopub.status.idle":"2023-03-24T19:10:19.658706Z","shell.execute_reply.started":"2023-03-24T19:10:19.648230Z","shell.execute_reply":"2023-03-24T19:10:19.657467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Class","metadata":{}},{"cell_type":"code","source":"class Helper:\n    @staticmethod\n    def resize(images, target_size):\n        return tf.image.resize(images, target_size, method='bilinear')\n    \n    @staticmethod\n    def augment(image, mask, probability=0.2):\n        do_flip = tf.random.uniform(shape=[], minval=0, maxval=1, dtype=tf.float32) < probability\n        \n        if do_flip:\n            image = tf.image.flip_left_right(image)\n            mask = tf.image.flip_left_right(mask)\n        \n        return image, mask\n    \n    @staticmethod\n    def preprocess(instance, target_size=IMAGE_SIZE, augment=False):\n        image, mask = instance['image'], instance['segmentation_mask']\n\n        # Resize the image\n        image = Helper.resize(image, target_size)\n        mask = Helper.resize(mask, target_size)\n        \n        # Augment the images randomly\n        if augment:\n            image, mask = Helper.augment(image, mask)\n        \n        # Normalize the images\n        image = (tf.cast(image, tf.float32) - 127.5) / 127.5\n        \n        # Map classes 1, 2, 3 to classes 0, 1, 2 \n        mask = mask - 1\n        \n        return image, mask\n    \n    @staticmethod\n    def plot(images, cmap=MASK_CMAP, titles=None, fig_size=(10, 10), is_BGR=True, n_cols=7):\n        \"\"\"\n        This method allows you to display a collection of images in a grid, with titles for each image.\n\n        Parameters:\n        - `images` (list): A list of images.\n        - `titles` (list, optional): A list of strings, representing the title for each image. The length of `titles` should be equal to the length of `images`.\n        - `fig_size` (tuple): The size of the figure.\n        - `is_BGR` (bool, optional): Indicates whether the input images are in BGR format (default is True).\n        - `n_cols` (int, optional): The number of columns in the grid (default is 3).\n\n        Returns:\n        None\n        \"\"\"\n\n        # Check if the images and the titles have the same length\n        if titles is not None and len(images) != len(titles):\n            raise ValueError(\"Images and titles must have the same length\")\n\n        # Calculate the number of rows required for the figure\n        n_rows = int(np.ceil(len(images) / n_cols))\n\n        # Create the fig\n        fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=fig_size)\n\n        for ax, img, title in itertools.zip_longest(axes.flat, images, titles or []):\n            if is_BGR:\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n            ax.imshow(img, cmap=cmap)\n            if titles is not None:\n                ax.set_title(title)\n\n            # Remove the tick labels\n            ax.set_yticklabels([])\n            ax.set_xticklabels([])\n\n        fig.tight_layout()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:10:19.660666Z","iopub.execute_input":"2023-03-24T19:10:19.661548Z","iopub.status.idle":"2023-03-24T19:10:19.677935Z","shell.execute_reply.started":"2023-03-24T19:10:19.661504Z","shell.execute_reply":"2023-03-24T19:10:19.676712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"# Load and split the Oxford-IIIT Pets dataset\n(train_data, test_data), info = tfds.load(\"oxford_iiit_pet\", split=['train', 'test'], with_info=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:10:19.679953Z","iopub.execute_input":"2023-03-24T19:10:19.680476Z","iopub.status.idle":"2023-03-24T19:11:43.809848Z","shell.execute_reply.started":"2023-03-24T19:10:19.680394Z","shell.execute_reply":"2023-03-24T19:11:43.808336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess\ntrain_data = train_data.map(lambda i : Helper.preprocess(i, augment=True), num_parallel_calls=tf.data.AUTOTUNE)\ntest_data = test_data.map(lambda i : Helper.preprocess(i, augment=False), num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:11:43.811742Z","iopub.execute_input":"2023-03-24T19:11:43.812912Z","iopub.status.idle":"2023-03-24T19:11:44.227912Z","shell.execute_reply.started":"2023-03-24T19:11:43.812866Z","shell.execute_reply":"2023-03-24T19:11:44.226662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to batched dataset\ntrain_data = train_data.cache().batch(BATCH_SIZE)\ntrain_data = train_data.prefetch(tf.data.AUTOTUNE)\n\ntest_data = test_data.cache().batch(BATCH_SIZE)\ntest_data = test_data.prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:11:44.229641Z","iopub.execute_input":"2023-03-24T19:11:44.230831Z","iopub.status.idle":"2023-03-24T19:11:44.252576Z","shell.execute_reply.started":"2023-03-24T19:11:44.230790Z","shell.execute_reply":"2023-03-24T19:11:44.251439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"random_index = int(tf.random.uniform(shape=[], minval=1, maxval=BATCH_SIZE, dtype=tf.int32))\nprint(random_index)\n\nbatch = next(iter((train_data)))\nimage, mask = batch[0][random_index], batch[1][random_index]\nHelper.plot([image, mask], cmap=MASK_CMAP, titles=['Image', 'Mask'], fig_size=(8,8), is_BGR=False, n_cols=2)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:11:44.254106Z","iopub.execute_input":"2023-03-24T19:11:44.255353Z","iopub.status.idle":"2023-03-24T19:11:45.946056Z","shell.execute_reply.started":"2023-03-24T19:11:44.255308Z","shell.execute_reply":"2023-03-24T19:11:45.944838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model","metadata":{}},{"cell_type":"markdown","source":"### Model architecture based on https://arxiv.org/abs/1505.04597","metadata":{}},{"cell_type":"code","source":"def downsample_block(inputs, filters, kernel_size=3, padding='same', strides=1):\n    x = layers.Conv2D(filters, kernel_size, strides, padding, activation='relu', use_bias=False, kernel_initializer = \"he_normal\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.25)(x)\n    \n    x = layers.Conv2D(filters, kernel_size, strides, padding, activation='relu', use_bias=False, kernel_initializer = \"he_normal\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.25)(x)\n    \n    return x\n\ndef upsample_block(inputs, filters, skip_connection, kernel_size=3, padding='same', strides=1):\n    x = layers.UpSampling2D()(inputs)\n    x = layers.Concatenate(axis=-1)([x, skip_connection])\n    \n    x = layers.Conv2D(filters, kernel_size, strides, padding, activation='relu', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.25)(x)\n    \n    x = layers.Conv2D(filters, kernel_size, strides, padding, activation='relu', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.25)(x)\n    \n    return x\n\ndef build_UNet(input_shape=(*IMAGE_SIZE, 3), n_output_channels=N_CLASSES):\n    input_layer = layers.Input(shape=input_shape)\n    \n    # Encoder\n    # 128 x 128 => 64 x 64\n    down1 = downsample_block(inputs=input_layer, filters=64)\n    pool1 = layers.MaxPooling2D((2, 2))(down1)\n    \n    # 64 x 64 => 32 x 32\n    down2 = downsample_block(inputs=pool1, filters=128)\n    pool2 = layers.MaxPooling2D((2, 2))(down2)\n    \n    # 32 x 32 => 16 x 16\n    down3 = downsample_block(inputs=pool2, filters=256)\n    pool3 = layers.MaxPooling2D((2, 2))(down3)\n    \n    # 16 x 16 => 8 x 8\n    down4 = downsample_block(inputs=pool3, filters=512)\n    pool4 = layers.MaxPooling2D((2, 2))(down4)\n    \n    # Final convolutional layer\n    encoder_outputs = layers.Conv2D(1024, (3, 3), padding='same', activation='relu')(pool4)\n    \n    # Decoder\n    # 8 x 8 => 16 x 16\n    up4 = upsample_block(inputs=pool4, filters=512, skip_connection=down4)\n    \n    # 16 x 16 => 32 x 32\n    up3 = upsample_block(inputs=up4, filters=256, skip_connection=down3)\n    \n    # 32 x 32 => 64 x 64\n    up2 = upsample_block(inputs=up3, filters=128, skip_connection=down2)\n    \n    # 64 x 64 => 128 x 128\n    up1 = upsample_block(inputs=up2, filters=64, skip_connection=down1)\n    \n    # Output\n    decoder_outputs = layers.Conv2D(n_output_channels, (1, 1), strides=1, activation='softmax')(up1)\n    \n    # Create the model\n    model = keras.models.Model(inputs=[input_layer], outputs=[decoder_outputs], name=\"U-Net\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:25:57.036121Z","iopub.execute_input":"2023-03-24T19:25:57.037709Z","iopub.status.idle":"2023-03-24T19:25:57.066986Z","shell.execute_reply.started":"2023-03-24T19:25:57.037656Z","shell.execute_reply":"2023-03-24T19:25:57.065480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build and compile the model\nwith strategy.scope():\n    model = build_UNet(input_shape=(*IMAGE_SIZE, 3), \n                       n_output_channels=N_CLASSES)\n    \n    model.compile(optimizer=optimizers.Adam(),\n                  loss=losses.SparseCategoricalCrossentropy(),\n                  metrics='accuracy')\n\n# Print the model's summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:25:57.543132Z","iopub.execute_input":"2023-03-24T19:25:57.546032Z","iopub.status.idle":"2023-03-24T19:25:58.604929Z","shell.execute_reply.started":"2023-03-24T19:25:57.545985Z","shell.execute_reply":"2023-03-24T19:25:58.604027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the model's architecture\ntf.keras.utils.plot_model(model, show_shapes=True, dpi=65)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:25:58.606932Z","iopub.execute_input":"2023-03-24T19:25:58.607342Z","iopub.status.idle":"2023-03-24T19:25:59.727531Z","shell.execute_reply.started":"2023-03-24T19:25:58.607275Z","shell.execute_reply":"2023-03-24T19:25:59.726307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Stop training if the model doesn't improve for 7 epochs\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                              patience=EARLY_STOP_PATIENCE,\n                                              restore_best_weights=True,\n                                              verbose=1\n                                             )\n\n# Train the model\nhistory = model.fit(train_data,\n                    validation_data=test_data,\n                    epochs=EPOCHS,\n                    callbacks=[early_stop]\n                   )\n\n# Save the model\nmodel.save(f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}-UNet.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:26:07.925497Z","iopub.execute_input":"2023-03-24T19:26:07.926597Z","iopub.status.idle":"2023-03-24T19:46:27.261519Z","shell.execute_reply.started":"2023-03-24T19:26:07.926550Z","shell.execute_reply":"2023-03-24T19:46:27.260426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"# Plot the accuracy curve\nplt.plot(range(1, len(history.history['accuracy']) + 1),\n         history.history['accuracy'],\n         label=\"Train accuracy\"\n        )\nplt.plot(range(1, len(history.history['val_accuracy']) + 1),\n         history.history['val_accuracy'],\n         label=\"Validation accuracy\"\n        )\n\nplt.title(\"Accuracy\")\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:46:46.225298Z","iopub.execute_input":"2023-03-24T19:46:46.225955Z","iopub.status.idle":"2023-03-24T19:46:46.463047Z","shell.execute_reply.started":"2023-03-24T19:46:46.225916Z","shell.execute_reply":"2023-03-24T19:46:46.462065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss curve\nplt.plot(range(1, len(history.history['loss']) + 1),\n         history.history['loss'],\n         label=\"Train loss\"\n        )\nplt.plot(range(1, len(history.history['val_loss']) + 1),\n         history.history['val_loss'],\n         label=\"Validation loss\"\n        )\n\nplt.title(\"Loss\")\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:46:50.084842Z","iopub.execute_input":"2023-03-24T19:46:50.085566Z","iopub.status.idle":"2023-03-24T19:46:50.312484Z","shell.execute_reply.started":"2023-03-24T19:46:50.085526Z","shell.execute_reply":"2023-03-24T19:46:50.311534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_tests = 10\n\n# Select a random batch\nbatch = next(iter(test_data.shuffle(1000)))\n\n# Select 'n_tests' images to segment\nimages, masks = batch[0], batch[1]\nimages, masks = images[: n_tests], masks[: n_tests]\n\n# Segment the selected images\nsegmentations = model.predict(images)\n\n# Plot the segmented images\nto_plot = []\ntitles = []\nfor image, mask, segmented in zip(images, masks, segmentations):\n    to_plot.append(image)\n    to_plot.append(mask)\n    to_plot.append(segmented)\n    \n    titles.append('Original')\n    titles.append('Mask')\n    titles.append('Segmented')\n\nHelper.plot(to_plot, titles=titles, cmap=MASK_CMAP, n_cols=3, is_BGR=False, fig_size=(15, 30))","metadata":{"execution":{"iopub.status.busy":"2023-03-24T19:49:07.727217Z","iopub.execute_input":"2023-03-24T19:49:07.727944Z","iopub.status.idle":"2023-03-24T19:49:12.848148Z","shell.execute_reply.started":"2023-03-24T19:49:07.727905Z","shell.execute_reply":"2023-03-24T19:49:12.847113Z"},"trusted":true},"execution_count":null,"outputs":[]}]}